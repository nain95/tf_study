{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6803,
     "status": "ok",
     "timestamp": 1676592483915,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "QU4CaBrU2o2a",
    "outputId": "a1ea62fd-c592-4c9c-dd1f-6452527fd8e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting konlpy\n",
      "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
      "Collecting JPype1>=0.7.0\n",
      "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.6/465.6 KB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (23.0)\n",
      "Installing collected packages: JPype1, konlpy\n",
      "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
     ]
    }
   ],
   "source": [
    "pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1907,
     "status": "ok",
     "timestamp": 1676592485818,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "tR_9Wn_AtL4s"
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1676592485818,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "lwODOYVxtayz"
   },
   "outputs": [],
   "source": [
    "def morph(input_data):\n",
    "    stop_words = [')','(','{','}','[',']','\\\\', '.', '《', '》']\n",
    "    preprocessed = [data for data in kkma.morphs(input_data) if data not in stop_words]\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1676592485818,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "KgdIN5gWj3D9"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def preprocessing(df):\n",
    "    context_list = []\n",
    "    qas_list = []\n",
    "    for context in tqdm(df['data']):\n",
    "        for idx, paragraphs in enumerate(context['paragraphs']):\n",
    "            tmp_context = morph(paragraphs['context'])\n",
    "            if len(tmp_context) > 250:\n",
    "                continue\n",
    "            context_list.append(tmp_context)\n",
    "            for qas in paragraphs['qas']:\n",
    "                tmp_question = morph(qas['question'])\n",
    "                if len(tmp_question) > 250:\n",
    "                    continue\n",
    "                qas_list.append([tmp_question,morph(qas['answers'][0]['text']),idx])\n",
    "    return context_list, qas_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1062,
     "status": "ok",
     "timestamp": 1676592494340,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "xATMxUGxSG6J",
    "outputId": "d9beabd4-ed89-406f-f160-e7a8d37261aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "# df1 = pd.read_csv('/content/drive/MyDrive/korquad_qg_data/dev_question.txt', sep='\\t', header=None)\n",
    "# df2 = pd.read_csv('/content/drive/MyDrive/korquad_qg_data/dev_sentence_feat.txt', sep='\\t', header=None)\n",
    "# df3 = pd.read_csv('/content/drive/MyDrive/korquad_qg_data/dev_sentence_feat.txt', sep='\\t', header=None)\n",
    "# df4 = pd.read_csv('/content/drive/MyDrive/korquad_qg_data/dev_answer.txt', sep='\\t', header=None)\n",
    "\n",
    "with open('/content/drive/MyDrive/korquad_data/KorQuAD_v1.0_dev.json') as f:\n",
    "    js = json.loads(f.read())\n",
    "test_df = pd.DataFrame(js)\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5850,
     "status": "ok",
     "timestamp": 1676592501353,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "6F-BhY-GfEwg"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/korquad_data/KorQuAD_v1.0_train.json') as f:\n",
    "    js = json.loads(f.read())\n",
    "train_df = pd.DataFrame(js)\n",
    "dev_df = train_df[:int(len(train_df) * 0.1)]\n",
    "train_df = train_df[int(len(train_df) * 0.1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 448500,
     "status": "ok",
     "timestamp": 1676592949847,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "MhVHHzOuvKyo",
    "outputId": "93944ca1-5b6b-4533-8a02-9fd589f270b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [07:28<00:00,  3.16s/it]\n"
     ]
    }
   ],
   "source": [
    "dev_context_list, dev_qas_list = preprocessing(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNLwK2BD_NTK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 434547,
     "status": "ok",
     "timestamp": 1676593384383,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "hIRJYKZBtaRq",
    "outputId": "23ff8cfb-2860-428a-a45f-eb378068e0d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [07:14<00:00,  3.10s/it]\n"
     ]
    }
   ],
   "source": [
    "test_context_list, test_qas_list = preprocessing(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3961360,
     "status": "ok",
     "timestamp": 1676597345734,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "3WRkhG5yqOOW",
    "outputId": "f664e9d1-eb58-4586-878d-0f473ba1d809"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1278/1278 [1:06:01<00:00,  3.10s/it]\n"
     ]
    }
   ],
   "source": [
    "train_context_list, train_qas_list = preprocessing(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 994,
     "status": "ok",
     "timestamp": 1676597365584,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "SIZLyxF5mdN1"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "file_name = ['dev_context_list', 'dev_qas_list',\\\n",
    "            'test_context_list', 'test_qas_list',\\\n",
    "             'train_context_list', 'train_qas_list']\n",
    "for f_n in file_name:\n",
    "    with open('/content/drive/My Drive/' + f_n + '.csv','w',newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(eval(f_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1676526363181,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "0dnTU5VygBGd"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_vocab(f_name: str) -> dict:\n",
    "    vocab = defaultdict(int)\n",
    "    corpus = pd.read_csv(f_name)\n",
    "    for line in corpus:\n",
    "        tokens = line.strip().split(',')\n",
    "        for token in tokens:\n",
    "            vocab[\" \".join(list(token[2:-1])) + \"<\\w>\"] += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1676526267188,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "GHn9KmWxg1pF"
   },
   "outputs": [],
   "source": [
    "def get_tokens(vocab):\n",
    "    \"\"\"사전 내 등록된 토큰을 확인\"\"\"\n",
    "    result = defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        tokens = word.split()\n",
    "        for token in tokens:\n",
    "            result[token] += freq\n",
    "    return dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1676526303959,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "4JOjh-JBpIoa"
   },
   "outputs": [],
   "source": [
    "def get_stats(vocab):\n",
    "    \"\"\"사전을 활용한 바이그램 페어 구축\"\"\"\n",
    "    pairs = defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "    return dict(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1676526302442,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "xGMy7EkfpROM"
   },
   "outputs": [],
   "source": [
    "def merge_vocab(pair, vocab):\n",
    "    \"\"\"가장 자주 등장한 바이그램 페어를 엮어줌\"\"\"\n",
    "    result = defaultdict(int)\n",
    "    for word in vocab:\n",
    "        paired = word.replace(\" \".join(pair), \"\".join(pair))\n",
    "        result[paired] = vocab[word]\n",
    "    return dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJDo9mUDwTp4"
   },
   "outputs": [],
   "source": [
    "num_merges = 5\n",
    "\n",
    "for i in range(num_merges):\n",
    "    pairs = get_stats(vocab)\n",
    "    if not pairs:\n",
    "        break\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    vocab = merge_vocab(best, vocab)\n",
    "    tokens = get_tokens(vocab)\n",
    "    print(f\"Iter: {i+1}\\n\"\n",
    "          f\"Best pair: {best}\\n\"\n",
    "          f\"Tokens: {tokens}\\n\"\n",
    "          f\"Number of tokens: {len(tokens)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fd16P_6zgvN8"
   },
   "outputs": [],
   "source": [
    "vocab = get_vocab('/content/dev_context_list.csv')\n",
    "for a in list(vocab.keys())[:10]:\n",
    "    print(a, vocab[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 922152,
     "status": "ok",
     "timestamp": 1676528057440,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "aiifz1row5uc",
    "outputId": "eb00dfbd-f852-4914-d04e-8988c205cedc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [15:23<00:00, 10.83it/s]\n"
     ]
    }
   ],
   "source": [
    "num_merges = 10000\n",
    "\n",
    "for i in tqdm(range(num_merges)):\n",
    "    pairs = get_stats(vocab)\n",
    "    if not pairs:\n",
    "        break\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    vocab = merge_vocab(best, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1676526639437,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "59D_JHk3w-oW"
   },
   "outputs": [],
   "source": [
    "def get_token_len(token: str):\n",
    "    \"\"\"토큰 길이 계산: </w> 는 하나의 토큰 취급\"\"\"\n",
    "    if token.endswith(\"</w>\"):\n",
    "        # 구성 캐릭터 + </w>\n",
    "        return len(token[:-4]) + 1\n",
    "    return len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1676526640386,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "Ez2Mf09VxdJc"
   },
   "outputs": [],
   "source": [
    "def tokenize(text, sorted_tokens, unknown_token=\"</u>\"):\n",
    "    \"\"\"구축된 사전을 활용한 BPE 토크나이즈\"\"\"\n",
    "    text = text.strip()\n",
    "\n",
    "    if text == \"\":\n",
    "        return list()\n",
    "    if len(sorted_tokens) == 0:\n",
    "        return [unknown_token]\n",
    "\n",
    "    result = list()\n",
    "    # 사전 내 등록 단어 순회\n",
    "    for i in range(len(sorted_tokens)):\n",
    "        token = re.escape(sorted_tokens[i])\n",
    "\n",
    "        # 현재 순회 중인 단어가 입력 텍스트에 포함되는지 확인\n",
    "        matched = [(m.start(0), m.end(0)) for m in re.finditer(token, text)]\n",
    "\n",
    "        ## 단순히 포함되지 않은 것이라면, continue\n",
    "        ## 토큰 리스트를 다 돌았음에도 포함되지 않은 것이라면, [unk] 반환\n",
    "        if len(matched) == 0:\n",
    "            if i == (len(sorted_tokens) - 1):\n",
    "                return [unknown_token]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        ## 포함되면 해당 토큰의 시작점(들)을 저장\n",
    "        ends = [m[0] for m in matched]\n",
    "        print(f\"[{text}] 매치 토큰: {token} / 인덱스: {ends}\")\n",
    "\n",
    "        start = 0\n",
    "        for end in ends:\n",
    "            # 매치 토큰 이전에 위치한 서브 스트링에 대한 토크나이즈 진행 및 결과 추가\n",
    "            substring = text[start:end]\n",
    "            print(f\"[{text}] 서브 스트링: {substring} ({start}~{end})\")\n",
    "            result += tokenize(substring, sorted_tokens[i+1:])\n",
    "\n",
    "            # 매치 토큰 추가\n",
    "            result += [token]\n",
    "            print(f\"[{text}] 현재 토크나이즈 결과: {result}\")\n",
    "\n",
    "            # 매치 토큰 길이 만큼 start 인덱스 값 증가\n",
    "            start = end + len(token)\n",
    "\n",
    "        # 매치 토큰 이후에 위치한 서브 스트링에 대한 토크나이즈 진행 및 결과 추가\n",
    "        remainder = text[start:]\n",
    "        result += tokenize(remainder, sorted_tokens[i+1:])\n",
    "        break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1jDhTIrOxfeZ"
   },
   "outputs": [],
   "source": [
    "tokens = get_tokens(vocab)\n",
    "\n",
    "# 사전 내 토큰들 길이 순으로 정렬 후, 단어만 저장\n",
    "sorted_tokens = sorted(tokens.items(), key=lambda x: (get_token_len(x[0]), x[1]), reverse=True)\n",
    "sorted_tokens = [token for (token, _) in sorted_tokens]\n",
    "\n",
    "print(f\"사전 내 등록 단어:\\n{sorted_tokens}\\n\")\n",
    "t = '내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의 역할을 벗어난다\"는 의견이 제기되었다. 대표적인 예가 10차 개헌안 발표이다. 원로 헌법학자인 허영 경희대 석좌교수는 정부의 헌법개정안 준비 과정에 대해 \"청와대 비서실이 아닌 국무회의 중심으로 이뤄졌어야 했다\"고 지적했다. \\'국무회의의 심의를 거쳐야 한다\\'(제89조)는 헌법 규정에 충실하지 않았다는 것이다. 그러면서 \"법무부 장관을 제쳐놓고 민정수석이 개정안을 설명하는 게 이해가 안 된다\"고 지적했다. 민정수석은 국회의원에 대해 책임지는 법무부 장관도 아니고, 국민에 대해 책임지는 사람도 아니기 때문에 정당성이 없고, 단지 대통령의 신임이 있을 뿐이라는 것이다. 또한 국무총리 선출 방식에 대한 기자의 질문에 \"문 대통령도 취임 전에 국무총리에게 실질적 권한을 주겠다고 했지만 그러지 못하고 있다. 대통령비서실장만도 못한 권한을 행사하고 있다.\"고 답변했다.'\n",
    "words = [\"한한국ㅑ한국한국국ㅖ\", \"사랑합니다</w>\", \"야식</w> 안먹고</w> 참아보기</w>\", t]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"입력 단어: {format(word)}\\n\")\n",
    "    print(f\"입력 단어 토큰화 결과: {tokenize(word, sorted_tokens)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1676599011948,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "tal-KAYsTCZe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6369,
     "status": "ok",
     "timestamp": 1676599018943,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "miSU23tt2iX4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 4/4 [00:11<00:00,  2.77s/it]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from tqdm import tqdm\n",
    "all_sentences = ['<sos>', '<eos>']\n",
    "questions, answer_in, answer_out, question_in = [], [], [], []\n",
    "\n",
    "file_name = ['dev_context_list', 'dev_qas_list',\\\n",
    "             'train_context_list', 'train_qas_list']\n",
    "\n",
    "for f_n in tqdm(file_name):\n",
    "    corpus = pd.read_csv(f_n+'.csv')\n",
    "    for idx ,line in enumerate(corpus):\n",
    "        if line[-1] != ']':\n",
    "            continue    \n",
    "        if f_n[-8:-5] == 'qas':\n",
    "            line_list = ast.literal_eval(line)[0]\n",
    "            answer_in.append(['<sos>'] + line_list)\n",
    "            answer_out.append(line_list + ['<eos>'])\n",
    "            question_in.append(questions[int(ast.literal_eval(line)[2])])\n",
    "        else:\n",
    "            line_list = ast.literal_eval(line)\n",
    "            questions.append(line_list)\n",
    "        #all_sentences.append(line_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences = answer_in, vector_size = 768, window = 5, min_count = 5, workers = 4, sg = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.wv.vectors.shape)\n",
    "print(questions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer_que = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_que.fit_on_texts(question_in)\n",
    "encoder_input = tokenizer_que.texts_to_sequences(question_in)\n",
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "\n",
    "tokenizer_ans = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_ans.fit_on_texts(answer_in)\n",
    "tokenizer_ans.fit_on_texts(answer_out)\n",
    "\n",
    "decoder_input = tokenizer_ans.texts_to_sequences(answer_in)\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "\n",
    "decoder_target = tokenizer_ans.texts_to_sequences(answer_out)\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력의 크기(shape) : (35739, 250)\n",
      "디코더의 입력의 크기(shape) : (35739, 79)\n",
      "디코더의 레이블의 크기(shape) : (35739, 79)\n"
     ]
    }
   ],
   "source": [
    "print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n",
    "print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n",
    "print('디코더의 레이블의 크기(shape) :',decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_vocab_size = len(tokenizer_que.word_index) + 1\n",
    "tar_vocab_size = len(tokenizer_ans.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_que.word_index\n",
    "index_to_src = tokenizer_que.index_word\n",
    "tar_to_index = tokenizer_ans.word_index\n",
    "index_to_tar = tokenizer_ans.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤 시퀀스 : [30895  8908  3836 ...  2677  6620 26139]\n",
      "(35739, 79)\n",
      "(35739, 250)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print('랜덤 시퀀스 :',indices)\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "print(decoder_input.shape)\n",
    "print(encoder_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터의 개수 : 3573\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.1)\n",
    "print('검증 데이터의 개수 :',n_of_val)\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 source 데이터의 크기 : (32166, 250)\n",
      "훈련 target 데이터의 크기 : (32166, 79)\n",
      "훈련 target 레이블의 크기 : (32166, 79)\n",
      "테스트 source 데이터의 크기 : (3573, 250)\n",
      "테스트 target 데이터의 크기 : (3573, 79)\n",
      "테스트 target 레이블의 크기 : (3573, 79)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
    "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
    "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
    "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
    "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
    "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "hidden_units = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs) # 임베딩 층\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
    "encoder_lstm = LSTM(hidden_units, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
    "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(tar_vocab_size, hidden_units) # 임베딩 층\n",
    "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "\n",
    "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True) \n",
    "\n",
    "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
    "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# 모델의 입력과 출력을 정의.\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 08:24:05.966350: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\n",
      "2023-02-17 08:24:05.966407: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:438] Error retrieving driver version: PERMISSION_DENIED: could not open driver version path for reading: /proc/driver/nvidia/version\n",
      "2023-02-17 08:24:05.966418: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at cudnn_rnn_ops.cc:1554 : UNKNOWN: Fail to find the dnn implementation.\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "Graph execution error:\n\nRecvAsync is cancelled.\n\t [[{{node broadcast_weights_1/assert_broadcastable/AssertGuard/pivot_f/_15/_63}}]] [Op:__inference_train_function_44046]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[158], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mencoder_input_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_target_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoder_input_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_target_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mCancelledError\u001b[0m: Graph execution error:\n\nRecvAsync is cancelled.\n\t [[{{node broadcast_weights_1/assert_broadcastable/AssertGuard/pivot_f/_15/_63}}]] [Op:__inference_train_function_44046]"
     ]
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1425,
     "status": "ok",
     "timestamp": 1676599042229,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "JFXyFTYb2wqH",
    "outputId": "f1eef6ff-1db7-4180-9107-f56c8c4f2337",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50005\n",
      "<OOV>\t\t => \t1\n",
      "하\t\t => \t2\n",
      "ㄴ\t\t => \t3\n",
      "이\t\t => \t4\n",
      "는\t\t => \t5\n",
      "의\t\t => \t6\n",
      "을\t\t => \t7\n",
      "은\t\t => \t8\n",
      "?\t\t => \t9\n",
      "에\t\t => \t10\n",
      "었\t\t => \t11\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters='', lower=False, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(all_sentences)\n",
    "print(len(tokenizer.word_index))\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    print(f'{word}\\t\\t => \\t{idx}')\n",
    "    if idx > 10:\n",
    "        break\n",
    "VOCAB_SIZE = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 1414,
     "status": "ok",
     "timestamp": 1676599043638,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "cYNB4uabBKSq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_sequence = tokenizer.texts_to_sequences(questions)\n",
    "answer_in_sequence = tokenizer.texts_to_sequences(answer_in)\n",
    "answer_out_sequence = tokenizer.texts_to_sequences(answer_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1676599043639,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "QOshpJ9vuda1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35740\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 10\n",
    "question_padded = pad_sequences(question_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
    "answer_in_padded = pad_sequences(answer_in_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
    "answer_out_padded = pad_sequences(answer_out_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
    "print(len(answer_in_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1676599043639,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "XpCpo71ru3Ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1676599043639,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "orgDvo-3vxz5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim, input_length=time_steps, name='Embedding')\n",
    "        self.dropout = Dropout(0.2, name='Dropuot')\n",
    "        self.lstm = LSTM(units, return_state=True, return_sequences=True, name='LSTM')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.dropout(x)\n",
    "        x, hidden_state, cell_state = self.lstm(x)\n",
    "        return x, [hidden_state, cell_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1676599043639,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "kBmgPdmr0WrT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim, input_length=time_steps, name='Embedding')\n",
    "        self.dropout = Dropout(0.2, name='Dropout')\n",
    "        self.lstm = LSTM(units,\n",
    "                         return_state=True,\n",
    "                         return_sequences=True,\n",
    "                         name='LSTM'\n",
    "                         )\n",
    "        self.attention = Attention(name='Attention')\n",
    "        self.dense = Dense(VOCAB_SIZE, activation='softmax', name='Dense')\n",
    "\n",
    "    def call(self, inputs, initial_state):\n",
    "        encoder_inputs, decoder_inputs = inputs\n",
    "        x = self.embedding(decoder_inputs)\n",
    "        x = self.dropout(x)\n",
    "        x, hidden_state, cell_state = self.lstm(x, initial_state=initial_state)\n",
    "\n",
    "        key_value = tf.concat([initial_state[0][:, tf.newaxis, :], x[:, :-1, :]], axis=1)\n",
    "        attention_matrix = self.attention([key_value, encoder_inputs])\n",
    "        x = tf.concat([x, attention_matrix], axis=-1)\n",
    "\n",
    "        x = self.dense(x)\n",
    "        return x, hidden_state, cell_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1676599043640,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "expJ76UV4Wzf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(tf.keras.Model):\n",
    "    def __init__(self, units, vocab_size, embedding_dim, time_steps, start_token, end_token):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "        self.time_steps = time_steps\n",
    "        \n",
    "        self.encoder = Encoder(units, vocab_size, embedding_dim, time_steps)\n",
    "        self.decoder = Decoder(units, vocab_size, embedding_dim, time_steps)\n",
    "        \n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        if training:\n",
    "            encoder_inputs, decoder_inputs = inputs\n",
    "            encoder_outputs, context_vector = self.encoder(encoder_inputs)\n",
    "            decoder_outputs, _, _ = self.decoder((encoder_outputs, decoder_inputs), initial_state=context_vector)\n",
    "            return decoder_outputs\n",
    "        else:\n",
    "            x = inputs\n",
    "            encoder_outputs, context_vector = self.encoder(x)\n",
    "            target_seq = tf.constant([[self.start_token]], dtype=tf.float32)\n",
    "            results = tf.TensorArray(tf.int32, self.time_steps)\n",
    "            \n",
    "            for i in tf.range(self.time_steps):\n",
    "                decoder_output, decoder_hidden, decoder_cell = self.decoder((encoder_outputs, target_seq), initial_state=context_vector)\n",
    "                decoder_output = tf.cast(tf.argmax(decoder_output, axis=-1), dtype=tf.int32)\n",
    "                decoder_output = tf.reshape(decoder_output, shape=(1, 1))\n",
    "                results = results.write(i, decoder_output)\n",
    "                \n",
    "                if decoder_output == self.end_token:\n",
    "                    break\n",
    "                    \n",
    "                target_seq = decoder_output\n",
    "                context_vector = [decoder_hidden, decoder_cell]\n",
    "                \n",
    "            return tf.reshape(results.stack(), shape=(1, self.time_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1676599043640,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "lax4_pfp5Td-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot(padded):\n",
    "    one_hot_vector = np.zeros((len(answer_out_padded), MAX_LENGTH, VOCAB_SIZE))\n",
    "\n",
    "    for i, sequence in enumerate(answer_out_padded):\n",
    "        for j, index in enumerate(sequence):\n",
    "            one_hot_vector[i, j, index] = 1\n",
    "\n",
    "    return one_hot_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 6511,
     "status": "ok",
     "timestamp": 1676599050145,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "E_nxDXEv5VLk",
    "tags": []
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 133. GiB for an array with shape (35740, 10, 50006) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m answer_in_one_hot \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_one_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswer_in_padded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m answer_out_one_hot \u001b[38;5;241m=\u001b[39m convert_to_one_hot(answer_out_padded)\n",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m, in \u001b[0;36mconvert_to_one_hot\u001b[0;34m(padded)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_one_hot\u001b[39m(padded):\n\u001b[0;32m----> 2\u001b[0m     one_hot_vector \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43manswer_out_padded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_LENGTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVOCAB_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, sequence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(answer_out_padded):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j, index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sequence):\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 133. GiB for an array with shape (35740, 10, 50006) and data type float64"
     ]
    }
   ],
   "source": [
    "answer_in_one_hot = convert_to_one_hot(answer_in_padded)\n",
    "answer_out_one_hot = convert_to_one_hot(answer_out_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1676599050145,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "Wrg0lEUq5Wh_",
    "outputId": "4f3ab0f3-5760-4fe2-dfea-65aed48490d8",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 50006), (1, 50006))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_in_one_hot[0].shape, answer_in_one_hot[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1676599050145,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "zscAC9IZ5ZuL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_index_to_text(indexs, end_token): \n",
    "    \n",
    "    sentence = ''\n",
    "    \n",
    "    for index in indexs:\n",
    "        if index == end_token:\n",
    "            break;\n",
    "        if index > 0 and tokenizer.index_word[index] is not None:\n",
    "            sentence += tokenizer.index_word[index]\n",
    "        else:\n",
    "            sentence += ''\n",
    "            \n",
    "        sentence += ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1676599050145,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "41hLp3cm7MkS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 500\n",
    "BATCH_SIZE = 1\n",
    "EMBEDDING_DIM = 50\n",
    "TIME_STEPS = MAX_LENGTH\n",
    "START_TOKEN = tokenizer.word_index['<sos>']\n",
    "END_TOKEN = tokenizer.word_index['<eos>']\n",
    "\n",
    "UNITS = 32\n",
    "\n",
    "VOCAB_SIZE = len(tokenizer.word_index)+1\n",
    "DATA_LENGTH = len(questions)\n",
    "SAMPLE_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 3578,
     "status": "ok",
     "timestamp": 1676599053721,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "4d-gCS2g7Ncz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_path = 'model/training_checkpoint-6.ckpt'\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
    "                             save_weights_only=True,\n",
    "                             save_best_only=True, \n",
    "                             monitor='loss', \n",
    "                             verbose=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 651,
     "status": "ok",
     "timestamp": 1676599054359,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "1dIdVfBW7PV7",
    "outputId": "f1a70ae7-9d6d-470f-b3cf-458a4789f7d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 06:41:01.519099: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 06:41:01.537685: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 06:41:01.539121: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 06:41:01.542214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 06:41:01.542621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 06:41:01.542973: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 06:41:02.201665: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 06:41:02.201940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 06:41:02.201953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-02-17 06:41:02.202132: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 06:41:02.202171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7380 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1676599054359,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "RgPkRvqk7WzA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    seq2seq = Seq2Seq(UNITS, VOCAB_SIZE, EMBEDDING_DIM, TIME_STEPS, START_TOKEN, END_TOKEN)\n",
    "    seq2seq.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1676599054359,
     "user": {
      "displayName": "전인엽",
      "userId": "01108925022436623187"
     },
     "user_tz": -540
    },
    "id": "OqkygEhr7ZXZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#seq2seq.load_weights(checkpoint_path)\n",
    "def make_prediction(model, question_inputs):\n",
    "    results = model(inputs=question_inputs, training=False)\n",
    "    # 변환된 인덱스를 문장으로 변환\n",
    "    results = np.asarray(results).reshape(-1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "qKPSAuLK7ld3",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), <class 'gensim.models.word2vec.Word2Vec'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mseq2seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquestion_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer_in_padded\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# 랜덤한 샘플 번호 추출\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     samples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(DATA_LENGTH, size\u001b[38;5;241m=\u001b[39mSAMPLE_SIZE)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py:1081\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1078\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle input: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1083\u001b[0m             _type_name(x), _type_name(y)\n\u001b[1;32m   1084\u001b[0m         )\n\u001b[1;32m   1085\u001b[0m     )\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapter_cls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1087\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1088\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData adapters should be mutually exclusive for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1089\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandling inputs. Found multiple adapters \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1091\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), <class 'gensim.models.word2vec.Word2Vec'>"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    seq2seq.fit([question_padded, answer_in_padded],\n",
    "                answer_out_one_hot,\n",
    "                epochs=5,\n",
    "                batch_size=1, \n",
    "                callbacks=[checkpoint]\n",
    "               )\n",
    "    # 랜덤한 샘플 번호 추출\n",
    "    samples = np.random.randint(DATA_LENGTH, size=SAMPLE_SIZE)\n",
    "\n",
    "    # 예측 성능 테스트\n",
    "    for idx in samples:\n",
    "        question_inputs = question_padded[idx]\n",
    "        # 문장 예측\n",
    "        results = make_prediction(seq2seq, np.expand_dims(question_inputs, 0))\n",
    "        \n",
    "        # 변환된 인덱스를 문장으로 변환\n",
    "        results = convert_index_to_text(results, END_TOKEN)\n",
    "        \n",
    "        print(f'Q: {questions[idx]}')\n",
    "        print(f'A: {results}\\n')\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMjpctZ2xU0pjY0FBHa5rF0",
   "mount_file_id": "1NwvKIE_TpewfoGD4cA_JPckmcaimpgYu",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
